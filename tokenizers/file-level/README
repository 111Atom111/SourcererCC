README

This program tokenizes large corpus of software.

********* Tokenizer configuration *********
The tokenizer receives the following parameters, ALL available through the file config.ini:

[Main]
# Number of processes for multitasking
N_PROCESSES = 4
# Language configuration file (see below)
language_file = c.ini

[Folders/Files]
# List of projects to be tokenized
PATH_proj_paths = projects.txt
# Folder where the list of tokens will be created. This list has the format:
      project_id,file_id,#tokens,#unique_tokens,md5_hash_tokens@#@[token@@::@@frequency,...]
PATH_tokens_folder = /raid5/clopes/LIXO/tokens
# Folder with bookkeeping of folders. Has the following format:
#     project_id,file_id,file_path
PATH_bookkeeping_file_folder = /raid5/clopes/LIXO/bookkeeping_files
# Folder with the bookkeeping of projects. Has the following format:
#     project_id,project_path
PATH_bookkeeping_proj_folder = /raid5/clopes/LIXO/bookkeeping_projs
# List of projects successfully tokenized
PATH_projects_success = /raid5/clopes/LIXO/projects_success.txt
# File used for multitasking management
PATH_project_starting_index = /raid5/clopes/LIXO/project_starting_index.txt
# List of projects that failed to be tokenized
PATH_projects_fail = /raid5/clopes/LIXO/projects_fail.txt
# Folder where a tokenized mirror will be created. See the option 'mirror' below
PATH_mirror_repo = /raid5/clopes/LIXO/mirror_repo

********* Language configuration *********
The file c.ini contains: 

[Language]
# List of terminal symbols that will be escaped by the tokenizer. All the strings around
      this symbols (and spaces, tabs and newlines) will become tokens
separators = ; :: . -> [ ] ( ) ++ -- ~ ! - + & * .* ->* * / % << >> < > <= >= ++ != & ^ | && || ? == { } = # , " \\ : $
# File extensions to be tokenized
file_extensions = .cpp .hpp .c .h .C .cc .CPP .c++ .cp
# Symbols for inline and tagged comments. All the comments will be skipped
comment_inline = //
comment_open_tag = /*
comment_close_tag = */

********* Running the tokenizer *********
The tokenizer automatically searches for a local config.ini file.
To run, three options are available:

$ python tokenizer tar
# Runs the tokenizer expecting projects to be inside tar files.
$ python tokenizer folder
# Runs the tokenizer expecting projects to be inside normal system folders
$ python mirror
# Creates an exact mirror of the structure of the projects tokenized, but each
projects' folder contains a file with a list file_path@#@[token@@::@@frequency,...]

********* Questions/Suggestions *********
Please contact us at 
http://sourcerer.ics.uci.edu/
or
http://mondego.ics.uci.edu/



